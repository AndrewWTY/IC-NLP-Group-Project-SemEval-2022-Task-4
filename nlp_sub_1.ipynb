{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:53.888836Z",
     "iopub.status.busy": "2023-03-07T12:53:53.888326Z",
     "iopub.status.idle": "2023-03-07T12:53:59.216846Z",
     "shell.execute_reply": "2023-03-07T12:53:59.216001Z",
     "shell.execute_reply.started": "2023-03-07T12:53:53.888805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/dist-packages (1.9.4)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.1.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.11.3)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (18.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "# !pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.218934Z",
     "iopub.status.busy": "2023-03-07T12:53:59.218650Z",
     "iopub.status.idle": "2023-03-07T12:53:59.224364Z",
     "shell.execute_reply": "2023-03-07T12:53:59.223733Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.218907Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from urllib import request\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "# from textattack.augmentation import CheckListAugmenter, BackTranslationAugmenter, WordNetAugmenter, EasyDataAugmenter, CLAREAugmenter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.225511Z",
     "iopub.status.busy": "2023-03-07T12:53:59.225281Z",
     "iopub.status.idle": "2023-03-07T12:53:59.335744Z",
     "shell.execute_reply": "2023-03-07T12:53:59.335154Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.225490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\n"
     ]
    }
   ],
   "source": [
    "# dont_patronize_me.py\n",
    "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
    "module_name = module_url.split('/')[-1]\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.337445Z",
     "iopub.status.busy": "2023-03-07T12:53:59.337248Z",
     "iopub.status.idle": "2023-03-07T12:53:59.572575Z",
     "shell.execute_reply": "2023-03-07T12:53:59.571978Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.337427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "# official scorer evalutaion.py\n",
    "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/evaluation.py\"\n",
    "module_name = module_url.split('/')[-1]\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.573617Z",
     "iopub.status.busy": "2023-03-07T12:53:59.573435Z",
     "iopub.status.idle": "2023-03-07T12:53:59.577043Z",
     "shell.execute_reply": "2023-03-07T12:53:59.576350Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.573600Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define useful classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.577947Z",
     "iopub.status.busy": "2023-03-07T12:53:59.577779Z",
     "iopub.status.idle": "2023-03-07T12:53:59.582142Z",
     "shell.execute_reply": "2023-03-07T12:53:59.581445Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.577932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_weighs(data):\n",
    "    # ratio_n = data['label'].value_counts().loc[positive_lavel]/len(data)\n",
    "    # ratio_p = data['label'].value_counts().loc[negative_label]/len(data)\n",
    "\n",
    "    ratio_p = data['label'].sum()/len(data)\n",
    "    ratio_n = (1-data['label']).sum()/len(data)\n",
    "\n",
    "    # calculate weight for weighted random sampling\n",
    "    w_p = 1/np.sqrt(ratio_p)\n",
    "    w_n = 1/np.sqrt(ratio_n)\n",
    "\n",
    "    sample_weights = np.where(data['label'] == 1, w_p, w_n)\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.583635Z",
     "iopub.status.busy": "2023-03-07T12:53:59.583445Z",
     "iopub.status.idle": "2023-03-07T12:53:59.590879Z",
     "shell.execute_reply": "2023-03-07T12:53:59.590324Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.583616Z"
    }
   },
   "outputs": [],
   "source": [
    "class dpm_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, attributes, max_token_len: int = 128, sample=5000):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        self.sample = sample\n",
    "        sample_weights = get_sample_weighs(self.data)\n",
    "        self.sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights, num_samples=len(self.data))\n",
    "        # self.sampler = None\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "\n",
    "        communities = pd.get_dummies(self.data.community)\n",
    "        self.community_labels = communities.columns\n",
    "        self.data = self.data.join(communities)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        comment = str(item.text)\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        communities = torch.FloatTensor(item[self.community_labels])\n",
    "        tokens = self.tokenizer.encode_plus(comment,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_tensors='pt',\n",
    "                                            truncation=True,\n",
    "                                            padding='max_length',\n",
    "                                            max_length=self.max_token_len,\n",
    "                                            return_attention_mask=True)\n",
    "        return {'input_ids': tokens.input_ids.flatten(), 'attention_mask': tokens.attention_mask.flatten(), 'labels': attributes, 'communities': communities}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.591893Z",
     "iopub.status.busy": "2023-03-07T12:53:59.591719Z",
     "iopub.status.idle": "2023-03-07T12:53:59.597964Z",
     "shell.execute_reply": "2023-03-07T12:53:59.597348Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.591875Z"
    }
   },
   "outputs": [],
   "source": [
    "class dpm_Data_Module(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_raw, val_raw, test_raw, attributes, batch_size: int = 16, max_token_length: int = 256,  model_name='roberta-large'):\n",
    "        super().__init__()\n",
    "        self.train_raw = train_raw\n",
    "        self.val_raw = val_raw\n",
    "        self.test_raw = test_raw\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.train_dataset = dpm_Dataset(\n",
    "                self.train_raw, attributes=self.attributes, tokenizer=self.tokenizer)\n",
    "            self.val_dataset = dpm_Dataset(\n",
    "                self.val_raw, attributes=self.attributes, tokenizer=self.tokenizer, sample=None)\n",
    "\n",
    "        if stage == 'predict':\n",
    "            self.test_dataset = dpm_Dataset(\n",
    "                self.test_raw, attributes=self.attributes, tokenizer=self.tokenizer, sample=None)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, sampler=self.train_dataset.sampler)\n",
    "        # return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=4, sampler=None)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.598984Z",
     "iopub.status.busy": "2023-03-07T12:53:59.598752Z",
     "iopub.status.idle": "2023-03-07T12:53:59.611142Z",
     "shell.execute_reply": "2023-03-07T12:53:59.610418Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.598964Z"
    }
   },
   "outputs": [],
   "source": [
    "class dpm_Classifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(\n",
    "            config['model_name'], return_dict=True)\n",
    "        self.hidden = nn.Linear(self.pretrained_model.config.hidden_size +\n",
    "                                config['n_communities'], self.pretrained_model.config.hidden_size+config['n_communities'])\n",
    "        self.classifier = nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size+config['n_communities'], self.config['n_labels'])\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        # self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, communities, labels=None):\n",
    "        # roberta layer\n",
    "        output = self.pretrained_model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        # print(pooled_output.shape)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = torch.cat((pooled_output, communities), 1)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            # print(logits.view(-1, self.config['n_labels']).shape, labels.view(-1, self.config['n_labels']).shape)\n",
    "            loss = self.loss_func(\n",
    "                logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
    "            # loss = self.loss_func(logits,  labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        # self.log(\"train_loss \", loss, prog_bar = True, logger=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True,\n",
    "                 logger=True,  on_step=True, on_epoch=False)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"validation_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
    "        \n",
    "        total_steps = self.config['train_size']/self.config['batch_size']\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, warmup_steps, total_steps)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.613719Z",
     "iopub.status.busy": "2023-03-07T12:53:59.613539Z",
     "iopub.status.idle": "2023-03-07T12:53:59.616858Z",
     "shell.execute_reply": "2023-03-07T12:53:59.616219Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.613704Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.617562Z",
     "iopub.status.busy": "2023-03-07T12:53:59.617414Z",
     "iopub.status.idle": "2023-03-07T12:53:59.628261Z",
     "shell.execute_reply": "2023-03-07T12:53:59.627366Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.617548Z"
    }
   },
   "outputs": [],
   "source": [
    "class dpm_llrd_Classifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(\n",
    "            config['model_name'], return_dict=True)\n",
    "        self.hidden = nn.Linear(self.pretrained_model.config.hidden_size +\n",
    "                                config['n_communities'], self.pretrained_model.config.hidden_size+config['n_communities'])\n",
    "        self.classifier = nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size+config['n_communities'], self.config['n_labels'])\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        # self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, communities, labels=None):\n",
    "        # roberta layer\n",
    "        output = self.pretrained_model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        # print(pooled_output.shape)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = torch.cat((pooled_output, communities), 1)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            # print(logits.view(-1, self.config['n_labels']).shape, labels.view(-1, self.config['n_labels']).shape)\n",
    "            loss = self.loss_func(\n",
    "                logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
    "            # loss = self.loss_func(logits,  labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        # self.log(\"train_loss \", loss, prog_bar = True, logger=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True,\n",
    "                 logger=True,  on_step=True, on_epoch=False)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"validation_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
    "        \n",
    "        total_steps = self.config['train_size']/self.config['batch_size']\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        \n",
    "        def llrd_lambda(current_step):\n",
    "            num_warmup_steps = warmup_steps\n",
    "            layerwise_lr_factor = 0.96 # Your layerwise learning rate decay factor\n",
    "            num_layers = len(self.pretrained_model.encoder.layer) + 2 # Number of layers in your model\n",
    "            if current_step < num_warmup_steps:\n",
    "                return float(current_step) / float(max(1, num_warmup_steps))\n",
    "            else:\n",
    "                layer_lr_decay = layerwise_lr_factor ** (current_step - num_warmup_steps)\n",
    "                layer_lr_decay = min(max(layer_lr_decay, 5e-6), 1e-4) # Your minimum learning rate\n",
    "                return layer_lr_decay\n",
    "        \n",
    "        llrd_scheduler = LambdaLR(optimizer, lr_lambda =llrd_lambda)\n",
    "        \n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, warmup_steps, total_steps)\n",
    "        \n",
    "        return [optimizer], [llrd_scheduler, scheduler]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.629108Z",
     "iopub.status.busy": "2023-03-07T12:53:59.628905Z",
     "iopub.status.idle": "2023-03-07T12:53:59.633924Z",
     "shell.execute_reply": "2023-03-07T12:53:59.633265Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.629092Z"
    }
   },
   "outputs": [],
   "source": [
    "def textattack_aug(data, augmenter, positive_only=True, ignore_original=True):\n",
    "    # augmenter = CheckListAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "    if positive_only:\n",
    "        samples = data[data['label'] == 1]\n",
    "    else:\n",
    "        samples = data\n",
    "    # pos_sample = data\n",
    "    aug_df = pd.DataFrame([]) if ignore_original else data.copy()\n",
    "\n",
    "    for row in samples.itertuples():\n",
    "        text = row.text\n",
    "        # EDA pipeline\n",
    "        augmented_texts = augmenter.augment(text)\n",
    "        for new_sentence in augmented_texts:\n",
    "            aug_df = pd.concat([aug_df, pd.DataFrame(\n",
    "                {'par_id': row.par_id, 'community': row.community, 'text': new_sentence, 'label': row.label}, index=[len(aug_df)])])\n",
    "\n",
    "    return aug_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data of task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.635239Z",
     "iopub.status.busy": "2023-03-07T12:53:59.635065Z",
     "iopub.status.idle": "2023-03-07T12:53:59.705531Z",
     "shell.execute_reply": "2023-03-07T12:53:59.704922Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.635225Z"
    }
   },
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('.', '.')\n",
    "dpm.load_task1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.706814Z",
     "iopub.status.busy": "2023-03-07T12:53:59.706639Z",
     "iopub.status.idle": "2023-03-07T12:53:59.730773Z",
     "shell.execute_reply": "2023-03-07T12:53:59.730191Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.706798Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "    with open(outf_path, 'w') as outf:\n",
    "        for pi in p:\n",
    "            outf.write(','.join([str(k) for k in pi])+'\\n')\n",
    "\n",
    "\n",
    "trids = pd.read_csv('train_semeval_parids-labels.csv')\n",
    "teids = pd.read_csv('dev_semeval_parids-labels.csv')\n",
    "trids.par_id = trids.par_id.astype(str)\n",
    "teids.par_id = teids.par_id.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.731567Z",
     "iopub.status.busy": "2023-03-07T12:53:59.731401Z",
     "iopub.status.idle": "2023-03-07T12:53:59.736992Z",
     "shell.execute_reply": "2023-03-07T12:53:59.736201Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.731552Z"
    }
   },
   "outputs": [],
   "source": [
    "def rebuild_data(id, data, shuffle=False):\n",
    "    rows = []  # will contain par_id, label and text\n",
    "    for idx in range(len(id)):\n",
    "        parid = id.par_id[idx]\n",
    "        # print(parid)\n",
    "        # select row from original dataset to retrieve `text` and binary label\n",
    "        keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
    "        text = data.loc[data.par_id == parid].text.values[0]\n",
    "        label = data.loc[data.par_id == parid].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id': parid,\n",
    "            'community': keyword,\n",
    "            'text': text,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "    rebuilt_data = pd.DataFrame(rows)\n",
    "    # shuffle\n",
    "    if shuffle:\n",
    "        rebuilt_data.sample(frac=1)\n",
    "\n",
    "    return rebuilt_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:53:59.738015Z",
     "iopub.status.busy": "2023-03-07T12:53:59.737832Z",
     "iopub.status.idle": "2023-03-07T12:54:20.790359Z",
     "shell.execute_reply": "2023-03-07T12:54:20.789694Z",
     "shell.execute_reply.started": "2023-03-07T12:53:59.738000Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_data = rebuild_data(teids, dpm.train_task1_df)\n",
    "total_train_data = rebuild_data(trids, dpm.train_task1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.791601Z",
     "iopub.status.busy": "2023-03-07T12:54:20.791401Z",
     "iopub.status.idle": "2023-03-07T12:54:20.794576Z",
     "shell.execute_reply": "2023-03-07T12:54:20.793940Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.791583Z"
    }
   },
   "outputs": [],
   "source": [
    "# augmenter = CheckListAugmenter(\n",
    "#     pct_words_to_swap=0.2, transformations_per_example=4)\n",
    "# augmented_train_data = textattack_aug(total_train_data, augmenter)\n",
    "# augmented_train_data.drop_duplicates(subset=['text'], inplace=True)\n",
    "# augmented_train_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.795671Z",
     "iopub.status.busy": "2023-03-07T12:54:20.795494Z",
     "iopub.status.idle": "2023-03-07T12:54:20.798317Z",
     "shell.execute_reply": "2023-03-07T12:54:20.797791Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.795652Z"
    }
   },
   "outputs": [],
   "source": [
    "# augmented_train_data.to_csv('checklist_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.799467Z",
     "iopub.status.busy": "2023-03-07T12:54:20.799295Z",
     "iopub.status.idle": "2023-03-07T12:54:20.821092Z",
     "shell.execute_reply": "2023-03-07T12:54:20.820402Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.799452Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_train_data = pd.read_csv('checklist_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.822367Z",
     "iopub.status.busy": "2023-03-07T12:54:20.822174Z",
     "iopub.status.idle": "2023-03-07T12:54:20.827486Z",
     "shell.execute_reply": "2023-03-07T12:54:20.826781Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.822350Z"
    }
   },
   "outputs": [],
   "source": [
    "final_train_data = pd.concat([total_train_data, augmented_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pd.read_table('task4_test.tsv',names=['par_id','community','country','text'],index_col=0)\n",
    "final_test_data['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.828666Z",
     "iopub.status.busy": "2023-03-07T12:54:20.828492Z",
     "iopub.status.idle": "2023-03-07T12:54:20.834837Z",
     "shell.execute_reply": "2023-03-07T12:54:20.834251Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.828650Z"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     augmented_train_data = pd.read_csv('augmented_train_data.csv')\n",
    "# except Exception as e:\n",
    "#     augmenter = CheckListAugmenter(\n",
    "#         pct_words_to_swap=0.2, transformations_per_example=2)\n",
    "#     augmented_train_data = textattack_aug(total_train_data, augmenter)\n",
    "#     augmented_train_data.drop_duplicates(subset=['text'], inplace=True)\n",
    "#     augmented_train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # split train data into train and validation\n",
    "# train_data, val_data = train_test_split(augmented_train_data, test_size=0.2, random_state=42)  # Shuffle is True by default\n",
    "\n",
    "# train_data, val_data = train_test_split(final_train_data, test_size=0.2, random_state=42)  # Shuffle is True by default\n",
    "# train_data.reset_index(drop=True, inplace=True)\n",
    "# val_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.836008Z",
     "iopub.status.busy": "2023-03-07T12:54:20.835828Z",
     "iopub.status.idle": "2023-03-07T12:54:20.838655Z",
     "shell.execute_reply": "2023-03-07T12:54:20.838038Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.835991Z"
    }
   },
   "outputs": [],
   "source": [
    "# augmented_train_data = pd.read_csv('augmented_train_data.csv')\n",
    "# # BackTranslationAugmenter\n",
    "# augmenter = BackTranslationAugmenter(\n",
    "#     pct_words_to_swap=0.2, transformations_per_example=2)\n",
    "# aug_pos_df = textattack_aug(augmented_train_data, augmenter)\n",
    "# aug_pos_df.to_csv('bt_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.839627Z",
     "iopub.status.busy": "2023-03-07T12:54:20.839472Z",
     "iopub.status.idle": "2023-03-07T12:54:20.842119Z",
     "shell.execute_reply": "2023-03-07T12:54:20.841487Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.839613Z"
    }
   },
   "outputs": [],
   "source": [
    "# augmented_train_data.to_csv('augmented_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.843053Z",
     "iopub.status.busy": "2023-03-07T12:54:20.842897Z",
     "iopub.status.idle": "2023-03-07T12:54:20.845755Z",
     "shell.execute_reply": "2023-03-07T12:54:20.845144Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.843040Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CLAREAugmenter\n",
    "# augmenter = CLAREAugmenter(pct_words_to_swap=0.2,\n",
    "#                            transformations_per_example=5)\n",
    "# aug_pos_df = textattack_aug(total_train_data, augmenter)\n",
    "# aug_pos_df.to_csv('clare_augmented.csv', index=False)\n",
    "\n",
    "# # EasyDataAugmenter\n",
    "# augmenter = EasyDataAugmenter(\n",
    "#     pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "# aug_pos_df = textattack_aug(total_train_data, augmenter)\n",
    "# aug_pos_df.to_csv('eda_augmented.csv', index=False)\n",
    "\n",
    "# # BackTranslationAugmenter\n",
    "# augmenter = BackTranslationAugmenter(\n",
    "#     pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "# aug_pos_df = textattack_aug(total_train_data, augmenter)\n",
    "# aug_pos_df.to_csv('bt_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:20.846782Z",
     "iopub.status.busy": "2023-03-07T12:54:20.846624Z",
     "iopub.status.idle": "2023-03-07T12:54:21.558894Z",
     "shell.execute_reply": "2023-03-07T12:54:21.558233Z",
     "shell.execute_reply.started": "2023-03-07T12:54:20.846769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "attributes = ['label']\n",
    "batch_size = 16\n",
    "\n",
    "dpm_data_module = dpm_Data_Module(\n",
    "    final_train_data, dev_data, final_test_data, attributes=attributes, batch_size=batch_size)\n",
    "dpm_data_module.setup()\n",
    "config = {\n",
    "    # 'model_name': 'microsoft/deberta-v3-large',\n",
    "    'model_name': 'roberta-large',\n",
    "    'n_labels': len(attributes),\n",
    "    'batch_size': batch_size,\n",
    "    'lr': 1e-5,\n",
    "    'warmup': 0.2,\n",
    "    'train_size': len(dpm_data_module.train_dataloader()),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 10,\n",
    "    'n_communities': len(final_train_data.community.unique())\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:21.560047Z",
     "iopub.status.busy": "2023-03-07T12:54:21.559878Z",
     "iopub.status.idle": "2023-03-07T12:54:21.562830Z",
     "shell.execute_reply": "2023-03-07T12:54:21.562370Z",
     "shell.execute_reply.started": "2023-03-07T12:54:21.560031Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:21.563854Z",
     "iopub.status.busy": "2023-03-07T12:54:21.563640Z",
     "iopub.status.idle": "2023-03-07T12:54:21.573254Z",
     "shell.execute_reply": "2023-03-07T12:54:21.572781Z",
     "shell.execute_reply.started": "2023-03-07T12:54:21.563833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1692), started 0:52:14 ago. (Use '!kill 1692' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./tb_logs --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T12:54:21.576031Z",
     "iopub.status.busy": "2023-03-07T12:54:21.575850Z",
     "iopub.status.idle": "2023-03-07T13:24:56.440138Z",
     "shell.execute_reply": "2023-03-07T13:24:56.439509Z",
     "shell.execute_reply.started": "2023-03-07T12:54:21.576015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type              | Params\n",
      "-------------------------------------------------------\n",
      "0 | pretrained_model | RobertaModel      | 355 M \n",
      "1 | hidden           | Linear            | 1.1 M \n",
      "2 | classifier       | Linear            | 1.0 K \n",
      "3 | loss_func        | BCEWithLogitsLoss | 0     \n",
      "4 | dropout          | Dropout           | 0     \n",
      "-------------------------------------------------------\n",
      "356 M     Trainable params\n",
      "0         Non-trainable params\n",
      "356 M     Total params\n",
      "1,425.724 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f17c59b298c46269cfcf56cbb0fea55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89db8cc5bef84f258c1537302c17eeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3178f6c0da394b78b7ad7edc13d0ea16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438516bc429b4c5887006c542e4351a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651cf142aea34d63853d7a659e01acf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bc2e8e531a4898a7861ad2cdcb74a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c278cc4ec146a79e5cb66f5323dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = dpm_Classifier(config)\n",
    "model = dpm_llrd_Classifier(config)\n",
    "logger = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='validation_loss',\n",
    "    patience=1,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='validation_loss',\n",
    "    dirpath='./checkpoints/',\n",
    "    filename='sample-{epoch:02d}',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'],\n",
    "                     logger=logger,\n",
    "                     accelerator='gpu',\n",
    "                     devices=1,\n",
    "                     num_sanity_val_steps=50,\n",
    "                     callbacks=[early_stop_callback])\n",
    "trainer.fit(model, dpm_data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:24:56.441568Z",
     "iopub.status.busy": "2023-03-07T13:24:56.441371Z",
     "iopub.status.idle": "2023-03-07T13:24:56.445682Z",
     "shell.execute_reply": "2023-03-07T13:24:56.444914Z",
     "shell.execute_reply.started": "2023-03-07T13:24:56.441548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(model.pretrained_model.encoder.layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:49:24.835420Z",
     "iopub.status.busy": "2023-03-07T13:49:24.834940Z",
     "iopub.status.idle": "2023-03-07T13:49:24.839695Z",
     "shell.execute_reply": "2023-03-07T13:49:24.838811Z",
     "shell.execute_reply.started": "2023-03-07T13:49:24.835400Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_raw_comments(model, dm):\n",
    "    predictions = trainer.predict(model, datamodule=dm)\n",
    "    flattened_predictions = np.stack(\n",
    "        [torch.sigmoid(torch.Tensor(p)) for batch in predictions for p in batch])\n",
    "    return flattened_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on dev data\n",
    "dev_data_module = dpm_Data_Module(\n",
    "    [], [], dev_data, attributes=['label'], batch_size=16)\n",
    "dev_predictions = classify_raw_comments(model, dev_data_module)\n",
    "true_labels = np.array(dev_data[attributes])\n",
    "\n",
    "print(true_labels.shape)\n",
    "for i, attribute in enumerate(attributes):\n",
    "    print(classification_report(true_labels[:,i].astype(int), dev_predictions[:,i]>0.5))\n",
    "\n",
    "dev_results = np.where(dev_predictions > 0.5, 1, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:49:25.122923Z",
     "iopub.status.busy": "2023-03-07T13:49:25.122248Z",
     "iopub.status.idle": "2023-03-07T13:49:49.301951Z",
     "shell.execute_reply": "2023-03-07T13:49:49.301105Z",
     "shell.execute_reply.started": "2023-03-07T13:49:25.122902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b4cdd1125643a69d3bcfad9f81322f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 537it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2094, 1)\n"
     ]
    }
   ],
   "source": [
    "# true_labels = np.array(dev_data[attributes])\n",
    "# predictions = classify_raw_comments(model, dpm_data_module)\n",
    "# print(true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:49:49.303500Z",
     "iopub.status.busy": "2023-03-07T13:49:49.303298Z",
     "iopub.status.idle": "2023-03-07T13:49:49.311611Z",
     "shell.execute_reply": "2023-03-07T13:49:49.311034Z",
     "shell.execute_reply.started": "2023-03-07T13:49:49.303479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1895\n",
      "           1       0.52      0.67      0.59       199\n",
      "\n",
      "    accuracy                           0.91      2094\n",
      "   macro avg       0.74      0.80      0.77      2094\n",
      "weighted avg       0.92      0.91      0.92      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i, attribute in enumerate(attributes):\n",
    "#     print(attribute)\n",
    "#     print(classification_report(true_labels[:,i].astype(int), predictions[:,i]>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:49:49.314042Z",
     "iopub.status.busy": "2023-03-07T13:49:49.313900Z",
     "iopub.status.idle": "2023-03-07T13:49:49.350659Z",
     "shell.execute_reply": "2023-03-07T13:49:49.350047Z",
     "shell.execute_reply.started": "2023-03-07T13:49:49.314028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>community</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_0</th>\n",
       "      <td>@@7258997</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>us</td>\n",
       "      <td>In the meantime , conservatives are working to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_1</th>\n",
       "      <td>@@16397324</td>\n",
       "      <td>women</td>\n",
       "      <td>pk</td>\n",
       "      <td>In most poor households with no education chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_2</th>\n",
       "      <td>@@16257812</td>\n",
       "      <td>migrant</td>\n",
       "      <td>ca</td>\n",
       "      <td>The real question is not whether immigration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3</th>\n",
       "      <td>@@3509652</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gb</td>\n",
       "      <td>In total , the country 's immigrant population...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_4</th>\n",
       "      <td>@@477506</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ca</td>\n",
       "      <td>Members of the church , which is part of Ken C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3893</th>\n",
       "      <td>@@20319448</td>\n",
       "      <td>migrant</td>\n",
       "      <td>jm</td>\n",
       "      <td>In a letter dated Thursday to European Commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3894</th>\n",
       "      <td>@@9990672</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>au</td>\n",
       "      <td>They discovered that poor families with health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3895</th>\n",
       "      <td>@@37984</td>\n",
       "      <td>migrant</td>\n",
       "      <td>ca</td>\n",
       "      <td>She married at 19 , to Milan ( Emil ) Badovina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3896</th>\n",
       "      <td>@@9691377</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>us</td>\n",
       "      <td>The United Kingdom is n't going to devolve int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3897</th>\n",
       "      <td>@@26170085</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>ng</td>\n",
       "      <td>This moral battle informed the recent defectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            par_id      community country  \\\n",
       "t_0      @@7258997     vulnerable      us   \n",
       "t_1     @@16397324          women      pk   \n",
       "t_2     @@16257812        migrant      ca   \n",
       "t_3      @@3509652        migrant      gb   \n",
       "t_4       @@477506     vulnerable      ca   \n",
       "...            ...            ...     ...   \n",
       "t_3893  @@20319448        migrant      jm   \n",
       "t_3894   @@9990672  poor-families      au   \n",
       "t_3895     @@37984        migrant      ca   \n",
       "t_3896   @@9691377      immigrant      us   \n",
       "t_3897  @@26170085  poor-families      ng   \n",
       "\n",
       "                                                     text  \n",
       "t_0     In the meantime , conservatives are working to...  \n",
       "t_1     In most poor households with no education chil...  \n",
       "t_2     The real question is not whether immigration i...  \n",
       "t_3     In total , the country 's immigrant population...  \n",
       "t_4     Members of the church , which is part of Ken C...  \n",
       "...                                                   ...  \n",
       "t_3893  In a letter dated Thursday to European Commiss...  \n",
       "t_3894  They discovered that poor families with health...  \n",
       "t_3895  She married at 19 , to Milan ( Emil ) Badovina...  \n",
       "t_3896  The United Kingdom is n't going to devolve int...  \n",
       "t_3897  This moral battle informed the recent defectio...  \n",
       "\n",
       "[3832 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_test_data = pd.read_table('task4_test.tsv',names=['par_id','community','country','text'],index_col=0)\n",
    "# final_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:25:21.911045Z",
     "iopub.status.busy": "2023-03-07T13:25:21.910879Z",
     "iopub.status.idle": "2023-03-07T13:26:08.260649Z",
     "shell.execute_reply": "2023-03-07T13:26:08.260073Z",
     "shell.execute_reply.started": "2023-03-07T13:25:21.911031Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1650/3067392770.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  w_p = 1/np.sqrt(ratio_p)\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/tmp/ipykernel_1650/3067392770.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  w_p = 1/np.sqrt(ratio_p)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72b06ad187e421a8e6c36aa028bc484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 537it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions on test data\n",
    "final_test_data = pd.read_table('task4_test.tsv',names=['par_id','community','country','text'],index_col=0)\n",
    "\n",
    "# final_test_data = pd.read_csv('task4_test.tsv')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "final_test_data['label'] = 0\n",
    "final_test_dataset = dpm_Dataset(\n",
    "    final_test_data, attributes=None, tokenizer=tokenizer)\n",
    "final_test_data_module = dpm_Data_Module([], [], final_test_data, attributes=['label'], batch_size=16)\n",
    "test_predictions = classify_raw_comments(model, final_test_data_module)\n",
    "test_results = np.where(test_predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('dev.txt', dev_results, fmt='%d')\n",
    "np.savetxt('test.txt', test_results, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Baseline\n",
    "### bow + naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:52.859468Z",
     "iopub.status.busy": "2023-03-07T10:14:52.859220Z",
     "iopub.status.idle": "2023-03-07T10:14:52.867960Z",
     "shell.execute_reply": "2023-03-07T10:14:52.867492Z",
     "shell.execute_reply.started": "2023-03-07T10:14:52.859446Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:52.869983Z",
     "iopub.status.busy": "2023-03-07T10:14:52.869851Z",
     "iopub.status.idle": "2023-03-07T10:14:52.875137Z",
     "shell.execute_reply": "2023-03-07T10:14:52.874587Z",
     "shell.execute_reply.started": "2023-03-07T10:14:52.869969Z"
    }
   },
   "outputs": [],
   "source": [
    "df = final_train_data\n",
    "corpus = df['text'].tolist()\n",
    "binary_labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:52.877166Z",
     "iopub.status.busy": "2023-03-07T10:14:52.877015Z",
     "iopub.status.idle": "2023-03-07T10:14:53.178454Z",
     "shell.execute_reply": "2023-03-07T10:14:53.177973Z",
     "shell.execute_reply.started": "2023-03-07T10:14:52.877148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the corpus and transform the corpus into a BOW representation\n",
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:53.180840Z",
     "iopub.status.busy": "2023-03-07T10:14:53.180685Z",
     "iopub.status.idle": "2023-03-07T10:14:53.196421Z",
     "shell.execute_reply": "2023-03-07T10:14:53.195869Z",
     "shell.execute_reply.started": "2023-03-07T10:14:53.180823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a Naive Bayes classifier and fit it to the training data\n",
    "classifier_nb = MultinomialNB()\n",
    "classifier_nb.fit(bow, binary_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:53.198801Z",
     "iopub.status.busy": "2023-03-07T10:14:53.198660Z",
     "iopub.status.idle": "2023-03-07T10:14:53.254995Z",
     "shell.execute_reply": "2023-03-07T10:14:53.254395Z",
     "shell.execute_reply.started": "2023-03-07T10:14:53.198786Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = list(test_data.text)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "y_test = list(test_data.label)\n",
    "\n",
    "# Predict labels for the test data and calculate accuracy\n",
    "y_pred_nb = classifier_nb.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:53.257808Z",
     "iopub.status.busy": "2023-03-07T10:14:53.257626Z",
     "iopub.status.idle": "2023-03-07T10:14:53.265487Z",
     "shell.execute_reply": "2023-03-07T10:14:53.264938Z",
     "shell.execute_reply.started": "2023-03-07T10:14:53.257788Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "attibutes = ['labels']\n",
    "report = classification_report(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:53.267888Z",
     "iopub.status.busy": "2023-03-07T10:14:53.267734Z",
     "iopub.status.idle": "2023-03-07T10:14:53.271826Z",
     "shell.execute_reply": "2023-03-07T10:14:53.271255Z",
     "shell.execute_reply.started": "2023-03-07T10:14:53.267872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1895\n",
      "           1       0.36      0.36      0.36       199\n",
      "\n",
      "    accuracy                           0.88      2094\n",
      "   macro avg       0.65      0.65      0.65      2094\n",
      "weighted avg       0.88      0.88      0.88      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bow+logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:53.274017Z",
     "iopub.status.busy": "2023-03-07T10:14:53.273863Z",
     "iopub.status.idle": "2023-03-07T10:14:55.452673Z",
     "shell.execute_reply": "2023-03-07T10:14:55.452221Z",
     "shell.execute_reply.started": "2023-03-07T10:14:53.274004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lr = LogisticRegression(max_iter =1000)\n",
    "classifier_lr.fit(bow, binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:55.454877Z",
     "iopub.status.busy": "2023-03-07T10:14:55.454733Z",
     "iopub.status.idle": "2023-03-07T10:14:55.459476Z",
     "shell.execute_reply": "2023-03-07T10:14:55.459072Z",
     "shell.execute_reply.started": "2023-03-07T10:14:55.454863Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_lr = classifier_lr.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:55.461479Z",
     "iopub.status.busy": "2023-03-07T10:14:55.461331Z",
     "iopub.status.idle": "2023-03-07T10:14:55.488287Z",
     "shell.execute_reply": "2023-03-07T10:14:55.487830Z",
     "shell.execute_reply.started": "2023-03-07T10:14:55.461465Z"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:14:55.490355Z",
     "iopub.status.busy": "2023-03-07T10:14:55.490199Z",
     "iopub.status.idle": "2023-03-07T10:14:55.494046Z",
     "shell.execute_reply": "2023-03-07T10:14:55.493598Z",
     "shell.execute_reply.started": "2023-03-07T10:14:55.490341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1895\n",
      "           1       0.35      0.28      0.31       199\n",
      "\n",
      "    accuracy                           0.88      2094\n",
      "   macro avg       0.64      0.61      0.62      2094\n",
      "weighted avg       0.87      0.88      0.88      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:45.134156Z",
     "iopub.status.busy": "2023-03-07T10:46:45.133295Z",
     "iopub.status.idle": "2023-03-07T10:46:45.137668Z",
     "shell.execute_reply": "2023-03-07T10:46:45.137104Z",
     "shell.execute_reply.started": "2023-03-07T10:46:45.134139Z"
    }
   },
   "outputs": [],
   "source": [
    "test_results = np.where(predictions > 0.5, 1, 0)\n",
    "y_pred_plm = list(test_results.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:45.349143Z",
     "iopub.status.busy": "2023-03-07T10:46:45.348484Z",
     "iopub.status.idle": "2023-03-07T10:46:45.353098Z",
     "shell.execute_reply": "2023-03-07T10:46:45.352395Z",
     "shell.execute_reply.started": "2023-03-07T10:46:45.349118Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "incorrect_indices_plm = [i for i in range(len(y_test)) if (y_test[i] != y_pred_plm[i] and y_test[i] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:45.673807Z",
     "iopub.status.busy": "2023-03-07T10:46:45.673518Z",
     "iopub.status.idle": "2023-03-07T10:46:45.678012Z",
     "shell.execute_reply": "2023-03-07T10:46:45.677320Z",
     "shell.execute_reply.started": "2023-03-07T10:46:45.673787Z"
    }
   },
   "outputs": [],
   "source": [
    "incorrect_indices_nb = [i for i in range(len(y_test)) if (y_test[i] != y_pred_nb[i] and y_test[i] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:46.015744Z",
     "iopub.status.busy": "2023-03-07T10:46:46.015173Z",
     "iopub.status.idle": "2023-03-07T10:46:46.019706Z",
     "shell.execute_reply": "2023-03-07T10:46:46.019077Z",
     "shell.execute_reply.started": "2023-03-07T10:46:46.015721Z"
    }
   },
   "outputs": [],
   "source": [
    "incorrect_indices_lr = [i for i in range(len(y_test)) if (y_test[i] != y_pred_lr[i] and y_test[i] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:46.271199Z",
     "iopub.status.busy": "2023-03-07T10:46:46.270568Z",
     "iopub.status.idle": "2023-03-07T10:46:46.275429Z",
     "shell.execute_reply": "2023-03-07T10:46:46.274981Z",
     "shell.execute_reply.started": "2023-03-07T10:46:46.271177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_indices_plm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:46.705667Z",
     "iopub.status.busy": "2023-03-07T10:46:46.705106Z",
     "iopub.status.idle": "2023-03-07T10:46:46.709901Z",
     "shell.execute_reply": "2023-03-07T10:46:46.709336Z",
     "shell.execute_reply.started": "2023-03-07T10:46:46.705645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_indices_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:46:46.711078Z",
     "iopub.status.busy": "2023-03-07T10:46:46.710916Z",
     "iopub.status.idle": "2023-03-07T10:46:46.714804Z",
     "shell.execute_reply": "2023-03-07T10:46:46.714313Z",
     "shell.execute_reply.started": "2023-03-07T10:46:46.711063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_indices_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.047323Z",
     "iopub.status.busy": "2023-03-07T18:09:48.047048Z",
     "iopub.status.idle": "2023-03-07T18:09:48.050466Z",
     "shell.execute_reply": "2023-03-07T18:09:48.049987Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.047302Z"
    }
   },
   "outputs": [],
   "source": [
    "# # for length question \n",
    "# incorrect_data = df.iloc[incorrect_indices_plm]\n",
    "# word_counts = incorrect_data['text'].str.split().apply(len)\n",
    "# print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.214713Z",
     "iopub.status.busy": "2023-03-07T18:09:48.214466Z",
     "iopub.status.idle": "2023-03-07T18:09:48.217519Z",
     "shell.execute_reply": "2023-03-07T18:09:48.217016Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.214695Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# result = []\n",
    "\n",
    "# for index in incorrect_indices_nb:\n",
    "#     if index in incorrect_indices_lr and index not in incorrect_indices_plm and index not in result:\n",
    "#         result.append(index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.348591Z",
     "iopub.status.busy": "2023-03-07T18:09:48.348105Z",
     "iopub.status.idle": "2023-03-07T18:09:48.351086Z",
     "shell.execute_reply": "2023-03-07T18:09:48.350564Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.348571Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# sns.histplot(word_counts, kde=False, color='blue', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.441192Z",
     "iopub.status.busy": "2023-03-07T18:09:48.440996Z",
     "iopub.status.idle": "2023-03-07T18:09:48.443825Z",
     "shell.execute_reply": "2023-03-07T18:09:48.443344Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.441175Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.561778Z",
     "iopub.status.busy": "2023-03-07T18:09:48.561523Z",
     "iopub.status.idle": "2023-03-07T18:09:48.564428Z",
     "shell.execute_reply": "2023-03-07T18:09:48.563988Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.561758Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_data.loc[25].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:48.708865Z",
     "iopub.status.busy": "2023-03-07T18:09:48.708358Z",
     "iopub.status.idle": "2023-03-07T18:09:48.711737Z",
     "shell.execute_reply": "2023-03-07T18:09:48.711120Z",
     "shell.execute_reply.started": "2023-03-07T18:09:48.708845Z"
    }
   },
   "outputs": [],
   "source": [
    "# bins = pd.cut(word_counts, bins=range(0, max(word_counts)+30, 30))\n",
    "\n",
    "# # Get the table of word counts for each bin\n",
    "# word_count_table = word_counts.groupby(bins).count()\n",
    "\n",
    "# print(word_count_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T18:09:49.584830Z",
     "iopub.status.busy": "2023-03-07T18:09:49.584331Z",
     "iopub.status.idle": "2023-03-07T18:09:49.587495Z",
     "shell.execute_reply": "2023-03-07T18:09:49.586962Z",
     "shell.execute_reply.started": "2023-03-07T18:09:49.584810Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_data\n",
    "# sub_df = test_data[test_data['label'] == 1]\n",
    "# print(len(sub_df))\n",
    "# word_counts = sub_df['text'].str.split().apply(len)\n",
    "# bins = pd.cut(word_counts, bins=range(0, max(word_counts)+50, 30))\n",
    "\n",
    "# # # Get the table of word counts for each bin\n",
    "# word_count_table = word_counts.groupby(bins).count()\n",
    "\n",
    "# print(word_count_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
