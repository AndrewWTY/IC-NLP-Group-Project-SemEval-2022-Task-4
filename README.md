# NLP Coursework 2023

## Description
We used the Don’t Patronize Me! dataset and corresponding labels to develop a Roberta-based model that detects patronizing and condescending language (PCL). PCL can have negative effects in various contexts, damaging relationships and trust. We employed data preprocessing and fine-tuning techniques to improve the model’s binary classification performance. Our model achieved a 0.61 F1 score on positive labels, surpassing the baseline RoBERTa model by 0.13 on the dev dataset. Our model came first in the inschool ranking.
